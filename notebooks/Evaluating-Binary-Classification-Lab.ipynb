{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Evaluating Binary Classification Models\n",
    "How do you know if the model you have built is a good predictor of your output variable?  \n",
    "\n",
    "This lab will walk you through building several binary classification models using different model methodologies and then comparing the model predictions using evaulation tools such as accuracy, a confusion matrix or an ROC curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Prepare Model Data\n",
    "For this lab, we will be using the [Titanic data](https://www.kaggle.com/c/titanic) from Kaggle.  \n",
    "\n",
    "The goal of your models will be to predict whether a passenger survived or perished in the Titanic disaster.  Kaggle has provided a data set with the following columns:\n",
    " * <b>PassengerId</b>: Unique identifier for each passenger\n",
    " * <b>Survived</b>: Whether the passenger survived (1 = survived; 0 = died)\n",
    " * <b>Pclass</b>: Class of ticket purchased by the passenger (1 = 1st class; 2 = 2nd class; 3 = 3rd class)\n",
    " * <b>Name</b>: Passenger name\n",
    " * <b>Sex</b>: Gender of the passenger (male/female)\n",
    " * <b>Age</b>: Age of the passenger\n",
    " * <b>SibSp</b>: Number of siblings/spouses of passenger also aboard the Titanic\n",
    " * <b>Parch</b>: Number of parents/children of passenger also aboard the Titanic\n",
    " * <b>Ticket</b>: Ticket number of the passenger\n",
    " * <b>Cabin</b>: Cabin number of the passenger\n",
    " * <b>Fare</b>: Amount of money the passenger paid for his/her ticket\n",
    " * <b>Embarked</b>: Port of embarkation (where the passenger got on the ship)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import CSV Data\n",
    "You will be using the [pandas](https://pandas.pydata.org/docs/user_guide/index.html) python package to import the provided CSV into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the pandas package and \"nickname\" it \"pd\"\n",
    "import pandas as pd\n",
    "\n",
    "#Import the Titanic data using the \"read_csv\" function of pandas\n",
    "data = pd.read_csv('data_files/classification/titanic.csv')\n",
    "#Display the first ten rows of your dataframe\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Model Features\n",
    "The **Survived** column is the labeled output.  This is what your model is trying to predict.\n",
    "\n",
    "The rest of the data columns are possible input or feature variables for your model.  The data in these columns will be used to make our predictions.\n",
    "\n",
    "The goal of your model is to use the training data to build a model that generalizes well.  This means that it will make correct predictions on new, unseen data that you did not use to train the model.  Therefore, not all data columns will be useful for your model.  For example, the **PassengerID** column is a meaningless identifier.  The **Name** column is unique to each passenger so it will not have general predictive power.  \n",
    "\n",
    "For the purposes of this lab, you will be using the following data fields to build your classification models:\n",
    " * Pclass\n",
    " * Sex\n",
    " * Age\n",
    " * SibSp\n",
    " * Parch\n",
    " \n",
    " As extra practice, you can adjust the models you build by adding and removing columns (and even making your own feature column using a process called [feature engineering](https://en.wikipedia.org/wiki/Feature_engineering))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle Missing or Unknown Data\n",
    "You should check your data to see if there are any missing/unknown values.\n",
    "\n",
    "First, check the output column.\n",
    "\n",
    "*pandas* allows you to select a single column of a dataframe by indexing on the column name.  You can then use the *.isnull()* function to get a logical output (True if the value is null and False otherwise).  By summing this logical column, you will get a count of how many True (i.e., missing) values you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 missing rows in the Survived column.\n"
     ]
    }
   ],
   "source": [
    "#Count the number of missing/null values in the Survived column\n",
    "missing_survived = data['Survived'].isnull().sum()\n",
    "print('There are {} missing rows in the Survived column.'.format(missing_survived))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now do the same thing for the Age column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 177 missing rows in the Age column.\n"
     ]
    }
   ],
   "source": [
    "#Count the number of missing/null values in the Age column\n",
    "missing_age = data['Age'].isnull().sum()\n",
    "print('There are {} missing rows in the Age column.'.format(missing_age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 177 rows (out of a total of 891 rows of data in our dataset) that do not have an age value for the passenger.\n",
    "\n",
    "You could just remove those rows from your dataset, but that would mean throwing away about 20% of the data.  Instead, you can replace the missing data with a default value.  In this case, you should use the default value of the mean or average age of all passengers.\n",
    "\n",
    "The code below uses the *.fillna()* function of *pandas* to replace the missing ages with the average age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace missing/unknown age with the overall average age of all passengers\n",
    "\n",
    "#Calculate the average age for the non-null data\n",
    "avg_age = data['Age'][~data['Age'].isnull()].mean()\n",
    "\n",
    "#Replace the na values with average age\n",
    "data['Age'] = data['Age'].fillna(avg_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you should check the other input columns for missing/null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of missing/null values in the PClass column\n",
    "missing_pclass = ######Enter your code here#######\n",
    "\n",
    "#Count the number of missing/null values in the Sex column\n",
    "missing_sex = ######Enter your code here#######\n",
    "\n",
    "#Count the number of missing/null values in the SibSp column\n",
    "missing_sibsp = ######Enter your code here#######\n",
    "\n",
    "#Count the number of missing/null values in the Parch column\n",
    "missing_parch = ######Enter your code here#######\n",
    "\n",
    "print('There are {} missing rows in the PClass column.'.format(missing_pclass))\n",
    "print('There are {} missing rows in the Sex column.'.format(missing_sex))\n",
    "print('There are {} missing rows in the SibSp column.'.format(missing_sibsp))\n",
    "print('There are {} missing rows in the Parch column.'.format(missing_parch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle Categorical Data\n",
    "The **Sex** column contains categorical data.  The value is one of two categories: male or female.\n",
    "\n",
    "This type of data is meaningful to humans but can be hard for models to understand.  So instead, you will convert this to a [dummy variable](https://en.wikipedia.org/wiki/Dummy_variable_(statistics)).  This means you will be creating a single column that has a 1 if the passenger is male and a 0 if the passenger is female.  Note that you can always have one fewer dummy variables than categories (so in this case, 2 categories - 1 = 1 dummy variable) to fully describe the total set of categorical values (since each dummy variable has two values: true or 1 and false or 0).\n",
    "\n",
    "*pandas* has a *.get_dummies()* function, which can be used to create a new column in your dataframe called \"Male.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sex  Male\n",
       "0      male     1\n",
       "1    female     0\n",
       "2    female     0\n",
       "3    female     0\n",
       "4      male     1\n",
       "..      ...   ...\n",
       "886    male     1\n",
       "887  female     0\n",
       "888  female     0\n",
       "889    male     1\n",
       "890    male     1\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Turn \"Sex\" column into dummy variable\n",
    "data['Male'] = pd.get_dummies(data['Sex'], drop_first= True)\n",
    "\n",
    "#View the sex column and the new \"male\" dummy variable column side by side\n",
    "data[['Sex','Male']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and test datasets\n",
    "As mentioned earlier, you will ultimately want to see how your models perform on new, unseen data.  Therefore, you will need to reserve a portion of your dataset where you know the output (survived or died).  This will allow you to compare your model output with the true output.\n",
    "\n",
    "The [scikit-learn](https://scikit-learn.org/stable/user_guide.html) package in python has many useful functions for machine learning, including a function to split your data into training and test data sets.\n",
    "\n",
    "To split your dataframe into training and test datasets, you will utilize the [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) function from the *model_selection* subpackage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full dataset has 891 rows.\n",
      "The training dataset has 712 rows.\n",
      "The test dataset has 179 rows.\n"
     ]
    }
   ],
   "source": [
    "#Import the train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Create a dataframe with only the features (or predictor) variables\n",
    "features = data[['Pclass', 'Age', 'SibSp', 'Parch', 'Male']]\n",
    "#Create a dataframe of just the output column\n",
    "output = data['Survived']\n",
    "\n",
    "#Create a training and test split using an 80%/20% split\n",
    "features_train, \\\n",
    "features_test, \\\n",
    "output_train, \\\n",
    "output_test = train_test_split(features, output, test_size = 0.2, random_state = 123)\n",
    "\n",
    "#Count the rows in the training/test set.\n",
    "print('The full dataset has {} rows.'.format(output.count()))\n",
    "print('The training dataset has {} rows.'.format(output_train.count()))\n",
    "print('The test dataset has {} rows.'.format(output_test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Build Binary Classification Models\n",
    "You can now build your binary classification models.  Binary means the model will be predicting only one of two outcomes and classification means that we are predicting categories or classifications as our output (in this case survived/died or 1/0).\n",
    "\n",
    "There are many different algorithms and methodologies to build binary classification models.  For this lab, you will be using *scikit-learn* to build the following models:\n",
    " * [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    " * [Decision Tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    " * [K-Nearest Neighbors](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model for you to build is a Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Logistic Regression function from scikit-learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Create a base logistic regression model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "#Fit the model using your training data\n",
    "lr.fit(features_train, output_train)\n",
    "\n",
    "#Use the test data to make predictions of the outcome\n",
    "lr_pred = lr.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the pattern demonstrated above to build the Logistic Regression model, build the other two models in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUILD THE DECISION TREE MODEL\n",
    "#Import Decision Tree function from scikit-learn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Create a base Decision Tree model\n",
    "tree = ##Enter code to build base model##\n",
    "\n",
    "#Fit the model using your training data\n",
    "tree.fit(##Enter code to fit your model##)\n",
    "\n",
    "#Use the test data to make predictions of the outcome\n",
    "tree_pred = tree.pred(##Enter code to make predictions on the test data##)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUILD THE K-NEAREST NEIGHBOR MODEL\n",
    "#Import K-Nearest Neighbor function from scikit-learn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Create a base Decision Tree model\n",
    "knn = ##Enter code to build base model##\n",
    "\n",
    "#Fit the model using your training data\n",
    "##Enter code to fit your model##\n",
    "\n",
    "#Use the test data to make predictions of the outcome\n",
    "knn_pred = ##Enter code to make predictions on the test data##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Evaluate Classification Models\n",
    "How can you determine if the models you just built do a good job predicting the output on your test data set?  This is where evaluation metrics come into play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Score\n",
    "First, you can look at the test accuracy.  This is the percentage of the test dataset your model correctly predicted.  In order to calculate this metric, you need the \"true\" labels (which are stored in the *output_test* dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the Logistic Regression model is 80.4%.\n"
     ]
    }
   ],
   "source": [
    "#Import the accuracy score metric function from scikit-learn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Calculate the accuracy for the Logistic Regression model\n",
    "lr_accuracy = accuracy_score(output_test, lr_pred)\n",
    "\n",
    "print('The accuracy for the Logistic Regression model is {:.1%}.'.format(lr_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad!  This means your Logisitic Regression model is right 80.4% of the time on new data not used to train the model.\n",
    "\n",
    "Now you should calculate the accuracy scores for the decision tree and KNN models.  Which model has the highest accuracy score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the accuracy for the Decision Tree model\n",
    "tree_accuracy = ##Fill in your own code here##\n",
    "\n",
    "#Calculate the accuracy for the Decision Tree model\n",
    "knn_accuracy = ##Fill in your own code here##\n",
    "\n",
    "print('The accuracy for the Decision Tree model is {:.1%}.'.format(tree_accuracy))\n",
    "print('The accuracy for the K-Nearest Neighbors model is {:.1%}.'.format(knn_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "A confusion matrix compares the number of true positive and true negative values to false positive and false negative values.\n",
    "\n",
    "The confusion matrix is laid out as follows:   \n",
    "\n",
    "|  \\\\ | 0 | 1 |\n",
    "| - | - | - |\n",
    "| 0 | TN | FP |\n",
    "| 1 | FN | TP |\n",
    "\n",
    "The values along the top of the table are the predictions (0 for false or died and 1 for true or survived).  \n",
    "\n",
    "The values along the side of the table are the actual values for the passengers in the test data set.\n",
    "\n",
    "Values on the diagonals of the confusion matrix are correct predictions.  Values on the off-diagonal are incorrect predictions.\n",
    "\n",
    "Each cell is populated as follows:\n",
    " * True Negative (TN): The number of correct negative predictions (predicted value = actual value = 0)\n",
    " * False Negative (FN): The number of incorrect negative predictions (predicted value = 0; actual value = 1)\n",
    " * False Positive (FP): The number of incorrect positive predictions (predicted value = 1; actual value = 0)\n",
    " * True Positive (TP): The number of correct positive predictions (predicted value = actual value = 1)\n",
    " \n",
    "The sum of all values in the confusion matrix is the total number of rows in the prediction data set (179 rows for your test data set).\n",
    "\n",
    "The confusion matrix can also be used to calculate other evaluation metrics.  For example, the accuracy score can be calculated as follows:  \n",
    "<br><center>\n",
    "$\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0  93  21\n",
       "1  14  51"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the confusion matrix metric function from scikit-learn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Calculate the confusion matrix for the Logistic Regression model\n",
    "lr_cm = confusion_matrix(output_test, lr_pred)\n",
    "\n",
    "print('Logistic Regression Test Confusion Matrix')\n",
    "#Put the confusion matrix into a data frame (to make it pretty to print)\n",
    "pd.DataFrame(lr_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is your turn to calculate the confusion matrices for the Decision Tree and KNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the confusion matrix for the Decision Tree model\n",
    "tree_cm = ##Enter your code here##\n",
    "\n",
    "print('Decision Tree Test Confusion Matrix')\n",
    "#Put the confusion matrix into a data frame (to make it pretty to print)\n",
    "pd.DataFrame(tree_cm)\n",
    "\n",
    "#Calculate the confusion matrix for the KNN model\n",
    "knn_cm = ##Enter your code here##\n",
    "\n",
    "print('K-Nearest Neighbors Test Confusion Matrix')\n",
    "#Put the confusion matrix into a data frame (to make it pretty to print)\n",
    "pd.DataFrame(knn_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve\n",
    "The Receiver Operating Characteristic or [ROC Curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) is a measure of the true positive rate versus the false positive rate for a binary classification model.  \n",
    "<br>\n",
    "<center>\n",
    "$\\text{True Positive Rate} = \\frac{TP}{TP + FN}$  \n",
    "</center>\n",
    "<br>\n",
    "<center>\n",
    "$\\text{False Positive Rate} = \\frac{FP}{FP + TN}$\n",
    "</center>\n",
    "\n",
    "The true positive rate is also known as the *sensitivity* and the false positivity rate is also known as 1 - *specificity*.  \n",
    "A related metric is the AUC or area under the ROC curve.  This is conveniently calculated for you as part of scikit-learn's ROC curve function.  The AUC ranges from 0.5 (random guessing) to 1.0 (perfect prediction).\n",
    "\n",
    "The closer the ROC curve is to the upper left corner of the graph, the better your model predictions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAw/ElEQVR4nO3deXwV5dn/8c9FCBAgsqPsO1qQRY3iAoJYKbjjhmjdfqjlqbvVB1uta1vtI0+lVCtFpO5Q61aKFNE+ILiVzYiIgihbANmXsErI9ftjJvEkZDkhOeckOd/363VeOTNzz8w1Z07mmrlnzn2buyMiIsmrRqIDEBGRxFIiEBFJckoEIiJJTolARCTJKRGIiCQ5JQIRkSSnRCBJz8yONrNPzSzbzG5NdDxFMbN+Zrb0MOf9l5ldU9ExVWZmdqWZzUh0HFWFEkECmdmuiFeume2NGL7yMJY3y8yuL2F6ezPziHWsNLN7iih3rZl9bmZ7zOw7M3vazBoWKtPVzP5uZpvNbIeZLTKzO80spZh1H2FmY8xsdbju5eFw07JuZwz8NzDL3dPdfWx5F2ZmD5rZSxUQVz53n+PuRx/Out19iLs/X9Z1ht+V3eH+Wmtmfyhu/1Y27v6yuw9KdBxVhRJBArl7/bwXsBo4L2LcyzFcdcNwnZcAvzazs/ImmNkvgN8DdwMNgJOBdsC7ZlYrLNMJ+A+wBujh7g2AS4EMIL3wysL5/g10BwYDRwCnAluAk8oavJnVLOs8pWgHfHE4M8YglsqmV/hd6Q8MA/5fRa8gCT7Dys/d9aoEL2Al8OPwfQ3gHuAbgoPlq0DjcFod4KVw/HZgHnAk8FvgILAP2AU8WcQ62gMO1IwYNxe4O3x/RDjvZYXmqw9sBP5fOPwS8HYZtu16YANQv4QyDnSOGH4O+E34fgCQBYwCvgNeBL4Ezo0oXxPYDBwfDp8MfBR+Rp8BA4pZ7/8V+ty6EiTAF4BNwCrgPqBGWP5a4EPgCWBrXoyFlvkg8FIx6zufIOlsB2YBP4qYdjzwKZAN/B34W+HPIKLsKGBtWHYpcCZBkv0eOBBuy2dh2VnA9RHz3hB+ftnAkrzPLIp98irwVMTwuUBmuC0fAT3Lsi2F9meZv/MR++PbcD0rgCsjxn8QEc+p4Xw7wr+nRkybBTwS7tdsYAbQNNHHhHi+Eh6AXuGOKJgIbgc+AVoDtYG/AJPCaT8D/gnUBVKAE4AjwmkF/uGLWEd7IhIBwcFyDzA0HB4M5BCRKCLmfT4ihu+A68qwbZOB50spU1oiyCG4UqkNpAH3Ay9HlD8H+Cp83yo8aJwdHmDOCoebFbPuAp8bQRL4B8HVTXtgGTAinHZtGMstBMknrYjlPUgRiYAgyewO40klqJJaDtQKX6uA28JpFxEc1A9JBMDRBFdjLSP2a6fi1h25fQRXbmuBEwEDOgPtStsnwDHAeuCOcPh4gpODPgTfw2sIvsO1o9yWwvvzdsr4nQfqATuBo8NyLYDuEfvpg/B9Y2AbcFW4z4aHw00iPp9vwv2TFg4/luhjQjxfqhqqnH4G3OvuWe6+n+Cf+5LwEvoA0ITgH/Sguy9w951lXP5mM9sLfAz8GXgrHN8U2OzuOUXMsz6cTrj+9WVYX1nLFyUXeMDd97v7XuAV4HwzqxtOvyIcB/BTYJq7T3P3XHd/F5hPkBhKFNaBDwN+6e7Z7r4S+F+Cg0iede7+J3fPCWOJ1jCCK6l33f0AMJrgwHMqQVKuCYx19wPu/gbB1VpRDhIcLLuZWaq7r3T3b6KM4Xrgf9x9ngeWu/uqEsovNLPdBFcQswi+LxBcVfzF3f8Tfg+fB/aH2xHNthTen4f7nc8FjjWzNHdf7+5FVfGdA3zt7i+G+2wS8BVwXkSZv7r7sjCWV4HeJX2I1Y0SQeXUDnjTzLab2XaCf8KDBFVALwLvAJPNbJ2Z/Y+ZpZZx+U0JqnvuIjg7y5t/M9C0mDrbFuF0CM6uW5RhfWUtX5RN7r4vb8DdlxN8LueFyeB8fkgE7YBL8z6/8DPsG2UMTfnhjDbPKoKrjDxrDnMbWkYu191zw2W1Cqet9fAUtaT1hNt+O8HBcqOZTTazllHG0Ibg7DdaxxN8V4YRnP3XC8e3A35R6DNuE25HNNtSYH9yGN95d98dxjUSWG9mb5vZMUVsQ4HPPVR4n34X8X5PuM1JQ4mgcloDDHH3hhGvOu6+NjzDesjduxGcSZ4LXB3OF3VTsuGZ1f8S1I3/PBz9McFZ3UWRZc2sHjCE4IYvwHvAxWXYnveAn4TLKc4egkv/PEcVDrmIeSYRXOZfACwJD5AQfH4vFvr86rn7Y1HEupngDLRdxLi2BNUpJcUSjXWRyzUzIzh4riW4YmoVjsvTprgFufsr7t43XJ4TVLNEE9saoFNZgg6vHF4l+H7cH7Gc3xb6jOuGZ9vRbEvhOA/rO+/u77j7WQRJ/ivgmSI2ocDnHiq8T5OaEkHlNA74rZm1AzCzZmZ2Qfj+DDPrEVZh7CQ4aB0M59sAdCzjuh4D/tvM6rj7DuAh4E9mNtjMUs2sPcHNviyCMzOAB4BTzexxMzsqjKuzmb1U+DHT0IsE/+ivm9kxZlbDzJqY2a/MLK+6JhO4wsxSzGwwwVMqpZkMDAL+ix+uBiC4sXiemf0kXF4dMxtgZq1LW6C7HySoGvitmaWH++DOcJllUSNcb96rdrjcc8zszPAq7hcEifcjgoPsQeBmM6sZ7u8in6iy4HcPA8Nl7gP2UvA70N7MivvfngDcZWYnWKBz3vcsCo8BN4b7/BlgpJn1CZdTz8zOMbP0smxLhDJ/583sSDM7PzzB2E9wg/xgEcueBnQ1syvCeIYB3YCpUW53tadEUDn9EZgCzDCzbIKbaH3CaUcBrxH8Q3wJvM8PB6k/EtSrbjOzaJ+Hf5vgxtkNAO7+P8CvCOqvd/LDY6JnhnW3hPXRpxDcpPzCzHYArxPUw2cXXkE4348JztjeDZc7l6Aa5j9hsdsI6my3A1fyw32LYrn7eoKDzqkET6XkjV9DcJXwK4Inf9YQPA4b7ff9FoKbut8CHxAkmYlRzptnOMEBOu/1jbsvJbh/8SeCK4/zCB4Z/t7dvye4EhtB8Bn8lOBAtb+IZdcmOChvJqjSaE6wrRAkbYAtZraw8Izu/neCJ8xeIdhXbxHcTC2Vu39O8H27293nE3xnniT4/iwnuEFLGbclz+F852sQJNN1BE9w9eeHq9vIuLcQXEX8gqCa8r8JnjjbXLhssrKC1XgiUlmY2X+Ace7+10THUl7VaVuqI10RiFQSZtbfzI4Kqy+uAXoC0xMd1+GoTtuSDPSLPpHK42iC+wj1CZ7suSSs/qqKqtO2VHuqGhIRSXKqGhIRSXJVrmqoadOm3r59+0SHISJSpSxYsGCzuzcralqVSwTt27dn/vz5iQ5DRKRKMbNimxJR1ZCISJJTIhARSXJKBCIiSU6JQEQkySkRiIgkuZglAjObaGYbzWxxMdPNzMZa0In5IjM7PlaxiIhI8WJ5RfAcQdeHxRkCdAlfNwJPxzAWEREpRsx+R+Dus8O27ItzAfBC2IvRJ2bW0MxaqD0SEakqvli3g3cWf1d6wQqS0b4xp3ct8jdh5ZLIH5S1omD3dVnhuEMSgZndSHDVQNu2beMSnIhIaZ6e9Q1TF62nQF9sMTSyf6dqlwiK+uiKbAHP3ccD4wEyMjLUSp6IVAq57nRpXp9374ymQ73KK5GJIIuC/Zi2JuhpSEQk7qZ9vp5VW/aUaZ5vNu6OUTTxlchEMIWgT9PJBF3S7dD9ARFJhIO5zs2vLCT3MOobfvyj5hUfUJzFLBGY2SRgANDUzLIIOjxPBXD3cQQdSp9N0NfpHuC6WMUiIlISdyfX4dYzu/DzAZ3KNG+tlKr/c6xYPjU0vJTpDtwUq/WLSPXh7ry7ZAPrtu+NyfIPhlcCqTWMOqkpMVlHZVblmqEWkeQzYc4Kfjvty5ivp0XDtJivozJSIhCRSu3tRev57bQvOadHCx658NgiHzesCDVqGA3SUmO09MpNiUBEKhV3Z8feA2Rt28uSdTu57x+LObF9I/73sl5JWW0TD0oEIhJ3O/cdIGvrXtZs20PWtr1kbdvDmq3B37Xb9pK9Pye/bOfm9Rl/VYaSQAwpEYhIhdu9P4esbXtZs3VPcJAPD/Z543buyylQvl6tFNo0rkvrRmmc3LEJrRul5Q93bl6f2jWVBGJJiUBEAPjk2y1szN5fpnncnZ17DxxyoN+250CBcnVSa9C6UV3aNErj+LaNaNM4LRwODvYN66Zi8WqnQQ6hRCAibN/zPZeP/+Sw569VswatG6bRunFdjm3VIDijDw/ybRrXpUm9WjrQV2JKBCLC9wdzAbjtzC6c16tlmeZNr1OTZvVrU6OGDvRVlRKBiORrll6bzs3rJzoMiTMlApEk93nWDh6ZugSApvVrJTgaSQQlApEktXHnPh5/ZymvLcyicd1a/G5oDwZ1OyrRYUkCKBFIQq3bvpeVm6tHU75VycLV2/jzrG/IOejceHpHbjqjM0fUSc5f1YoSgSTYNRPn8vXGXYkOIykN7n4Uvzz7GNo1qZfoUCTBlAgkofZ8f5D+XZuVuelfKZ9G9WrR9cj0RIchlYQSgcTN1xuyCzQdALA/J5dm6bXp07FJgqISESUCiYvlG7M564nZRU6rW0vNB4gkkhKBxEVe2zK/OKsrPVo3KDDtuLaNEhGSiISUCKRcduw5wPqdpfcatWpL8GRQj9YNGHB01e/jVaQ6USKQcrn0Lx+xbEP0T/2oKWGRykeJQMplx94DnNa5CT/t067Usmm1UjixfeM4RCUiZaFEkIRyc52sbXtxvNzLOpjrtGlUlyE9WlRAZCKSCEoESWjMv79m7L+/rrDl1a5Zo8KWJSLxp0SQhLbu3k/92jV5+ILu5V6WGfTt3KwCohKRRFEiSFK1a9bgouNbJzoMEakEdE0vIpLklAhERJKcEoGISJJTIkgyubnOis27SVH/siISUiJIMo9N/4oPl2/hhn4dEx2KiFQSemqomnN3csPfjb30ySrGz/6Wq09px/X9OiQ2MBGpNJQIqrmLn/6Ihau35w+f1e1IHjivO2aqGhKRQEwTgZkNBv4IpAAT3P2xQtMbAC8BbcNYRrv7X2MZU7L5dvNuerVpyJnHNCe9Tk0uP7Gt7g+ISAExSwRmlgI8BZwFZAHzzGyKuy+JKHYTsMTdzzOzZsBSM3vZ3b+PVVzJqHfrBtx6ZpdEhyEilVQsrwhOApa7+7cAZjYZuACITAQOpFtQT1Ef2ArkFF6QlG7F5t0M/fOH7Nl/sMD47w/mqhpIREoUy0TQClgTMZwF9ClU5klgCrAOSAeGuXtu4QWZ2Y3AjQBt27aNSbBV3dpte9m+5wAX9m5Ji4Zp+eMN1JSEiJQolomgqNPQwu0e/wTIBAYCnYB3zWyOu+8sMJP7eGA8QEZGRvnbTq7Grjy5ndr8F5EyieXvCLKANhHDrQnO/CNdB7zhgeXACuCYGMYkIiKFxDIRzAO6mFkHM6sFXE5QDRRpNXAmgJkdCRwNfBvDmEREpJCYVQ25e46Z3Qy8Q/D46ER3/8LMRobTxwGPAM+Z2ecEVUmj3H1zrGISEZFDxfR3BO4+DZhWaNy4iPfrgEGxjKG6+/nLC1i4ajv7c4KnhfR8kIiUlX5ZXMV98PVmjjyiDv3bNqN+nZp0b9kg0SGJSBWjRFANnNa5KQ+eX/5uJ0UkOSkRVEFvfbqWsf/3NThk79fv70SkfJQIqqBPvt3C2m17GdT9KI5t1YALerdMdEgiUoUpEVRRDeum8qfhxyU6DBGpBtQxTRWzYvNuvvwuO9FhiEg1oiuCKmLBqq2Mn/0tM5ZsILVGDUb2Vw9jIlIxlAgqsYO5zrtLNvDMnG9ZsGobDdJSuWlAZ64+tR3N0+skOjwRqSaUCCqhfQcO8vrCLCbMWcGKzbtp3SiNB8/rxqUZbahXW7tMRCqWjiqVyNbd3/Pix6t44eOVbNn9PT1bN+DJK45jcPejqJmi2zkiEhtRJwIzq+fuu2MZTLJatWU3E+as4O8L1rDvQC4Dj2nODf06cnLHxupURkRirtREYGanAhMIehBra2a9gJ+5+89jHVxVsnHnPu59azH7DhwsvXCEfQcOMn/VNlJr1ODC41pyfb+OdD0yPUZRiogcKporgicIOpCZAuDun5nZ6TGNqgr6LGsH7y7ZwDFHpVO3VkrU85kZI/t34rpT29P8CN0AFpH4i6pqyN3XFKqiKNtpbxIZfWkvjm2lht9EpOqIJhGsCauHPOxg5lbgy9iGJSIi8RLNoygjgZsIOqPPAnoDuj8gIlJNRHNFcLS7Xxk5wsxOAz6MTUgiIhJP0VwR/CnKcSIiUgUVe0VgZqcApwLNzOzOiElHEPRBLCIi1UBJVUO1CH47UBOIfLB9J3BJLIMSEZH4KTYRuPv7wPtm9py7r4pjTCIiEkfR3CzeY2aPA92B/F88ufvAmEUlIiJxE83N4peBr4AOwEPASmBeDGMSEZE4iuaKoIm7P2tmt0VUF70f68CqislzV7N0Qzart+xJdCgiIoclmkRwIPy73szOAdYBrWMXUtVy/5QvwKF2ag1aNUzjqAZqL0hEqpZoEsFvzKwB8AuC3w8cAdwey6CqFIcR/TowavAxiY5EROSwlJoI3H1q+HYHcAbk/7I4qezan8NzH65gb6FmpnNycxMUkYhIxSjpB2UpwGUEbQxNd/fFZnYu8CsgDTguPiFWDh9/s4XRM5aRUsOIbIe1Zo0adGleP2FxiYiUV0lXBM8CbYC5wFgzWwWcAtzj7m/FIbZKJdcdgCk3n0b3lmpmWkSqj5ISQQbQ091zzawOsBno7O7fxSe0xFm2IZt3l2woMO7rDdkJikZEJLZKSgTfu3sugLvvM7NlZU0CZjYY+CNB20QT3P2xIsoMAMYAqcBmd+9flnXEwp9nLuetzHWHjK9fuybN0msnICIRkdgpKREcY2aLwvcGdAqHDXB371nSgsN7DE8BZxH0YzDPzKa4+5KIMg2BPwOD3X21mTU//E2pOAcdOjStxzu3F+yRM6WGkVJDncmLSPVSUiL4UTmXfRKw3N2/BTCzycAFwJKIMlcAb7j7agB331jOdVYYA2rVjOaH1yIiVVtJjc6Vt6G5VsCaiOEsoE+hMl2BVDObRdDC6R/d/YXCCzKzG4EbAdq2bVvOsEREJFIsT3mLqkPxQsM1gROAc4CfAL82s66HzOQ+3t0z3D2jWbNmFR+piEgSi+aXxYcri+Dx0zytCZqnKFxms7vvBnab2WygF7AshnEVaX/OQaZ9vp59B3JZtWV3vFcvIpIwUSUCM0sD2rr70jIsex7Qxcw6AGuBywnuCUT6B/CkmdUk6AinD/BEGdZRYT74ejN3/O2z/OE+HRonIgwRkbgrNRGY2XnAaIIDdQcz6w087O7nlzSfu+eY2c3AOwSPj0509y/MbGQ4fZy7f2lm04FFQC7BI6aLy7VFh+nAwaCpiBdHnESX5uk0qpeaiDBEROIumiuCBwmeAJoF4O6ZZtY+moW7+zRgWqFx4woNPw48Hs3y4qFp/dpqQVREkko0N4tz3H1HzCMREZGEiOaKYLGZXQGkmFkX4Fbgo9iGJSIi8RLNFcEtBP0V7wdeIWiO+vYYxiQiInEUzRXB0e5+L3BvrIMREZH4i+aK4A9m9pWZPWJm3WMekYiIxFWpicDdzwAGAJuA8Wb2uZndF+vAREQkPqJqYsLdv3P3scBIIBO4P5ZBiYhI/JSaCMzsR2b2oJktBp4keGKodcwjExGRuIjmZvFfgUnAIHc/tLcWERGp0kpNBO5+cjwCERGRxCg2EZjZq+5+mZl9TsHmo6PqoUxERKqGkq4Ibgv/nhuPQEREJDGKvVns7uvDtz9391WRL+Dn8QlPRERiLZrHR88qYtyQig5EREQSo6R7BP9FcObf0cwWRUxKBz6MdWAiIhIfJd0jeAX4F/AocE/E+Gx33xrTqEREJG5KSgTu7ivN7KbCE8yssZKBiEj1UNoVwbnAAoLHRy1imgMdYxiXiIjESbGJwN3PDf92iF84IiISb9G0NXSamdUL3//UzP5gZm1jH5qIiMRDNI+PPg3sMbNewH8Dq4AXYxqViIjETbSd1ztwAfBHd/8jwSOkIiJSDUTT+mi2mf0SuAroZ2YpQGpswxIRkXiJ5opgGEHH9f/P3b8DWgGPxzQqERGJm2i6qvwOeBloYGbnAvvc/YWYRyYiInERzVNDlwFzgUuBy4D/mNklsQ5MRETiI5p7BPcCJ7r7RgAzawa8B7wWy8BERCQ+okkENfKSQGgLUXZ6XxUMHjObrzfuIteDvndSalgpc4iIVC/RJILpZvYOQb/FENw8nha7kOJr6YZsMto1ok+HJjRIS6Vzs/qJDklEJK6i6bP4bjO7COhL0N7QeHd/M+aRxdEpHZtw56CjEx2GiEhClNQfQRdgNNAJ+By4y93XxiswERGJj5Lq+icCU4GLCVog/VNZF25mg81sqZktN7N7Sih3opkd1NNIIiLxV1LVULq7PxO+X2pmC8uy4PAXyE8RdHWZBcwzsynuvqSIcr8H3inL8kVEpGKUlAjqmNlx/NAPQVrksLuXlhhOApa7+7cAZjaZoL2iJYXK3QK8DpxYxthFRKQClJQI1gN/iBj+LmLYgYGlLLsVsCZiOAvoE1nAzFoBQ8NlFZsIzOxG4EaAtm3VAraISEUqqWOaM8q57KIeyPdCw2OAUe5+0Kz45/fdfTwwHiAjI6PwMkREpByi+R3B4coC2kQMtwbWFSqTAUwOk0BT4Gwzy3H3t2IYl4iIRIhlIpgHdDGzDsBa4HLgisgCkd1gmtlzwFQlARGR+IpZInD3HDO7meBpoBRgort/YWYjw+njYrVuERGJXqmJwIJ6myuBju7+cNhf8VHuPre0ed19GoWaoyguAbj7tVFFLCIiFSqaxuP+DJwCDA+Hswl+HyAiItVANFVDfdz9eDP7FMDdt5lZrRjHJSIicRLNFcGB8Ne/Dvn9EeTGNCoREYmbaBLBWOBNoLmZ/Rb4APhdTKMSEZG4iaYZ6pfNbAFwJsGPxC509y9jHpmIiMRFNE8NtQX2AP+MHOfuq2MZmIiIxEc0N4vfJrg/YEAdoAOwFOgew7hERCROoqka6hE5bGbHAz+LWUQiIhJXZe6EPmx+Wk1Gi4hUE9HcI7gzYrAGcDywKWYRiYhIXEVzjyA94n0OwT2D12MTjoiIxFuJiSD8IVl9d787TvGIiEicFXuPwMxquvtBgqogERGppkq6IphLkAQyzWwK8Hdgd95Ed38jxrGJiEgcRHOPoDGwhaBf4bzfEzigRCAiUg2UlAiah08MLeaHBJBH/QaLiFQTJSWCFKA+0XVCLyIiVVRJiWC9uz8ct0jiaMGqrUzJXAeAK6WJSJIrKREUdSVQLfz1w5VM+3w9R6Sl0qReLbq1PCLRIYmIJExJieDMuEURZw50aFqPf/9iQKJDERFJuGJ/R+DuW+MZiIiIJEaZG50TEZHqRYlARCTJKRGIiCQ5JQIRkSSnRCAikuSUCEREkpwSgYhIklMiEBFJckoEIiJJLqaJwMwGm9lSM1tuZvcUMf1KM1sUvj4ys16xjEdERA4Vs0QQ9nf8FDAE6AYMN7NuhYqtAPq7e0/gEWB8rOIREZGixfKK4CRgubt/6+7fA5OBCyILuPtH7r4tHPwEaB3DeEREpAixTAStgDURw1nhuOKMAP5V1AQzu9HM5pvZ/E2bNlVgiCIiEstEEHXPZmZ2BkEiGFXUdHcf7+4Z7p7RrFmzCgxRRESi6bz+cGUBbSKGWwPrChcys57ABGCIu2+JYTwiIlKEWF4RzAO6mFkHM6sFXA5MiSxgZm2BN4Cr3H1ZDGMREZFixOyKwN1zzOxm4B0gBZjo7l+Y2chw+jjgfqAJ8GczA8hx94xYxSQiIoeKZdUQ7j4NmFZo3LiI99cD18cyBhERKZl+WSwikuSUCEREkpwSgYhIklMiEBFJckoEIiJJLqZPDVUm7s6yDbvYn3OQHXsOJDocEZFKI2kSwZyvN3P1xLn5wz1aNUhgNCIilUfSJILsfTkAPHxBd1o1TKPrkekJjkhEpHJImkSQ5+SOTZQEREQi6GaxiEiSUyIQEUlySgQiIklOiUBEJMkpEYiIJDklAhGRJKdEICKS5JQIRESSnBKBiEiSUyIQEUlySgQiIklOiUBEJMklXaNzUr0cOHCArKws9u3bl+hQRCqFOnXq0Lp1a1JTU6OeR4lAqrSsrCzS09Np3749ZpbocEQSyt3ZsmULWVlZdOjQIer5VDUkVdq+ffto0qSJkoAIYGY0adKkzFfISgRS5SkJiPzgcP4flAhERJKcEoFIOdWvX7/cy5g/fz633nprsdNXrlzJK6+8EnV5gPbt29OjRw969uxJ//79WbVqVbnjrCjjxo3jhRdeqJBlrV+/nnPPPbfAuNtuu41WrVqRm5ubP+7BBx9k9OjRBcq1b9+ezZs3A/Ddd99x+eWX06lTJ7p168bZZ5/NsmXLyhXb/v37GTZsGJ07d6ZPnz6sXLmyyHKTJk3K31eDBw/Oj+mOO+6gd+/e9O7dm65du9KwYUMANm3axODBg8sVWyQlApFKICMjg7FjxxY7vXAiKK18npkzZ7Jo0SIGDBjAb37zm3LH6e4FDq6Ha+TIkVx99dXlXg7AH/7wB2644Yb84dzcXN58803atGnD7Nmzo1qGuzN06FAGDBjAN998w5IlS/jd737Hhg0byhXbs88+S6NGjVi+fDl33HEHo0aNOqRMTk4Ot912W/6+6tmzJ08++SQATzzxBJmZmWRmZnLLLbdw0UUXAdCsWTNatGjBhx9+WK748uipIak2HvrnFyxZt7NCl9mt5RE8cF73Ms+XmZnJyJEj2bNnD506dWLixIk0atSIefPmMWLECOrVq0ffvn3517/+xeLFi5k1axajR49m6tSpvP/++9x2221AUN87e/Zs7rnnHr788kt69+7NNddcw3HHHZdffteuXdxyyy3Mnz8fM+OBBx7g4osvLhDPKaeckp84Nm3axMiRI1m9ejUAY8aM4bTTTmPTpk1cccUVbNmyhRNPPJHp06ezYMECdu3axZAhQzjjjDP4+OOPeeutt3j11Vd59dVX2b9/P0OHDuWhhx5i9+7dXHbZZWRlZXHw4EF+/etfM2zYMO655x6mTJlCzZo1GTRoEKNHj+bBBx+kfv363HXXXcV+VgMGDKBPnz7MnDmT7du38+yzz9KvX79DPuvXX3+9QJKbOXMmxx57LMOGDWPSpEkMGDCg1P01c+ZMUlNTGTlyZP643r17l3W3H+If//gHDz74IACXXHIJN998M+5eoB7f3XF3du/eTZMmTdi5cyedO3c+ZFmTJk3ioYceyh++8MILefnllznttNPKHaeuCERi4Oqrr+b3v/89ixYtokePHvn/wNdddx3jxo3j448/JiUlpch5R48ezVNPPUVmZiZz5swhLS2Nxx57jH79+pGZmckdd9xRoPwjjzxCgwYN+Pzzz1m0aBEDBw48ZJnTp0/nwgsvBIJqkzvuuIN58+bx+uuvc/311wPw0EMPMXDgQBYuXMjQoUPzEwXA0qVLufrqq/n0009ZunQpX3/9NXPnziUzM5MFCxYwe/Zspk+fTsuWLfnss89YvHgxgwcPZuvWrbz55pt88cUXLFq0iPvuuy/qzwqCs+W5c+cyZsyYAuPzrFixgkaNGlG7du38cZMmTWL48OEMHTqUqVOncuDAgeJ2U77FixdzwgknlFoOoF+/fvnVNZGv995775Cya9eupU2bNgDUrFmTBg0asGXLlgJlUlNTefrpp+nRowctW7ZkyZIljBgxokCZVatWsWLFigL7NiMjgzlz5kQVc2l0RSDVxuGcucfCjh072L59O/379wfgmmuu4dJLL2X79u1kZ2dz6qmnAnDFFVcwderUQ+Y/7bTTuPPOO7nyyiu56KKLaN26dYnre++995g8eXL+cKNGjfLfn3HGGWzYsIHmzZvnnzW/9957LFmyJL/Mzp07yc7O5oMPPuDNN98EYPDgwQWW065dO04++WQAZsyYwYwZMzjuuOMA2LVrF19//TX9+vXjrrvuYtSoUZx77rn069ePnJwc6tSpw/XXX88555xzSF1+cZ9VnryqkBNOOKHI+vX169fTrFmz/OHvv/+eadOm8cQTT5Cenk6fPn2YMWMG55xzTrFP05T1KZuyHHzdvdT1HThwgKeffppPP/2Ujh07csstt/Doo48WSJqTJ0/mkksuKXDy0Lx5c9atW1em2IsT0ysCMxtsZkvNbLmZ3VPEdDOzseH0RWZ2fCzjEUmkog4KRbnnnnuYMGECe/fu5eSTT+arr74qdbnFHcxmzpzJqlWr6N69O/fffz8Q1KF//PHH+XXPa9euJT09vcT46tWrV2B9v/zlL/PnX758OSNGjKBr164sWLCAHj168Mtf/pKHH36YmjVrMnfuXC6++GLeeuutMt/gzDvTT0lJIScn55DpaWlpBZ6Znz59Ojt27KBHjx60b9+eDz74gEmTJgHQpEkTtm3bVmD+7OxsGjZsSPfu3VmwYEFUMZXliqB169asWbMGCK5uduzYQePGjQuUyczMBKBTp06YGZdddhkfffRRgTKTJ09m+PDhBcbt27ePtLS0qGIuTcwSgZmlAE8BQ4BuwHAz61ao2BCgS/i6EXg6VvGIxEuDBg1o1KhR/pnjiy++SP/+/WnUqBHp6el88sknAAXO4iN988039OjRg1GjRpGRkcFXX31Feno62dnZRZYfNGhQ/s1F4JCDXVpaGmPGjOGFF15g69ath5TPOxD17duXV199FQjO+gsvJ89PfvITJk6cyK5du4Cg+mPjxo2sW7eOunXr8tOf/pS77rqLhQsXsmvXLnbs2MHZZ5/NmDFj8tdV2mcVra5duxa4Upg0aRITJkxg5cqVrFy5khUrVjBjxgz27NnD6aefzpQpU/I/xzfeeINevXqRkpLCwIED2b9/P88880z+subNm8f7779/yDrnzJmTnwQjXz/+8Y8PKXv++efz/PPPA/Daa68xcODAQ5J2q1atWLJkCZs2bQLg3Xff5Uc/+lH+9KVLl7Jt2zZOOeWUAvMtW7aMY489NurPqiSxrBo6CVju7t8CmNlk4AJgSUSZC4AXPDgV+cTMGppZC3dfH8O4RCrUnj17ClTf3HnnnTz//PP5N0A7duzIX//6VyB4iuSGG26gXr16DBgwgAYNGhyyvDFjxjBz5kxSUlLo1q0bQ4YMoUaNGtSsWZNevXpx7bXX5lfLANx3333cdNNNHHvssaSkpPDAAw/kV6nkadGiBcOHD+epp55i7Nix3HTTTfTs2ZOcnBxOP/10xo0bxwMPPMDw4cP529/+Rv/+/WnRogXp6en5B/w8gwYN4ssvv8w/MNWvX5+XXnqJ5cuXc/fdd1OjRo38eu/s7GwuuOAC9u3bh7vzxBNPHLK9xX1W0ahXrx6dOnVi+fLltGzZknfeeYe//OUvBab37duXf/7znwwbNoybb76Zvn37YmY0b96cCRMmAEF1zZtvvsntt9/OY489Rp06dWjfvj1jxoyJOpaijBgxgquuuorOnTvTuHHjAsm/d+/eZGZm0rJlSx544AFOP/10UlNTadeuHc8991x+uUmTJnH55ZcfkkBmzpzJOeecU6748uXdsa7oF3AJMCFi+CrgyUJlpgJ9I4b/DWQUsawbgfnA/LZt2/rhmL9yq//XS/N97bY9hzW/VE5LlixJdAhlkp2dnf/+0Ucf9VtvvTWB0RS0b98+P3DggLu7f/TRR96rV6/EBhSlN954w++9995EhxF3/fr1861btxY5raj/C2C+F3O8juUVQVGVloUrIaMpg7uPB8YDZGRkRFfRWsgJ7RpxQrvongoQiZW3336bRx99lJycnEPO/BJt9erVXHbZZeTm5lKrVq0C1SSV2dChQw95Eqe627RpE3feeWeBG/rlEctEkAW0iRhuDRS+xR1NGZFqY9iwYQwbNizRYRSpS5cufPrpp4kO47DkPQKbLJo1a5b/OHBFiOVTQ/OALmbWwcxqAZcDUwqVmQJcHT49dDKww3V/QMrIo3waRyQZHM7/Q8yuCNw9x8xuBt4BUoCJ7v6FmY0Mp48DpgFnA8uBPcB1sYpHqqc6deqwZcsWNUUtwg/9EdSpU6dM81lVO5vKyMjw+fPnJzoMqSTUQ5lIQcX1UGZmC9w9o6h59MtiqdJSU1PL1BOTiBxKbQ2JiCQ5JQIRkSSnRCAikuSq3M1iM9sEHG5XS02BzRUYTlWgbU4O2ubkUJ5tbufuzYqaUOUSQXmY2fzi7ppXV9rm5KBtTg6x2mZVDYmIJDklAhGRJJdsiWB8ogNIAG1zctA2J4eYbHNS3SMQEZFDJdsVgYiIFKJEICKS5KplIjCzwWa21MyWm9k9RUw3MxsbTl9kZscnIs6KFMU2Xxlu6yIz+8jMeiUizopU2jZHlDvRzA6a2SXxjC8WotlmMxtgZplm9oWZHdrpbhUTxXe7gZn908w+C7e5SrdibGYTzWyjmS0uZnrFH7+K67qsqr4Imrz+BugI1AI+A7oVKnM28C+CHtJOBv6T6LjjsM2nAo3C90OSYZsjyv0fQZPnlyQ67jjs54YE/YK3DYebJzruOGzzr4Dfh++bAVuBWomOvRzbfDpwPLC4mOkVfvyqjlcEJwHL3f1bd/8emAxcUKjMBcALHvgEaGhmLeIdaAUqdZvd/SN33xYOfkLQG1xVFs1+BrgFeB3YGM/gYiSabb4CeMPdVwO4e1Xf7mi22YF0CzqkqE+QCHLiG2bFcffZBNtQnAo/flXHRNAKWBMxnBWOK2uZqqSs2zOC4IyiKit1m82sFTAUGBfHuGIpmv3cFWhkZrPMbIGZXR236GIjmm1+EvgRQTe3nwO3uXtufMJLiAo/flXH/giK6qaq8DOy0ZSpSqLeHjM7gyAR9I1pRLEXzTaPAUa5+8Fq0ntZNNtcEzgBOBNIAz42s0/cfVmsg4uRaLb5J0AmMBDoBLxrZnPcfWeMY0uUCj9+VcdEkAW0iRhuTXCmUNYyVUlU22NmPYEJwBB33xKn2GIlmm3OACaHSaApcLaZ5bj7W3GJsOJF+93e7O67gd1mNhvoBVTVRBDNNl8HPOZBBfpyM1sBHAPMjU+IcVfhx6/qWDU0D+hiZh3MrBZwOTClUJkpwNXh3feTgR3uvj7egVagUrfZzNoCbwBXVeGzw0ilbrO7d3D39u7eHngN+HkVTgIQ3Xf7H0A/M6tpZnWBPsCXcY6zIkWzzasJroAwsyOBo4Fv4xplfFX48avaXRG4e46Z3Qy8Q/DEwUR3/8LMRobTxxE8QXI2sBzYQ3BGUWVFuc33A02AP4dnyDlehVtujHKbq5VottndvzSz6cAiIBeY4O5FPoZYFUS5nx8BnjOzzwmqTUa5e5VtntrMJgEDgKZmlgU8AKRC7I5famJCRCTJVceqIRERKQMlAhGRJKdEICKS5JQIRESSnBKBiEiSUyKQSilsLTQz4tW+hLK7KmB9z5nZinBdC83slMNYxgQz6xa+/1WhaR+VN8ZwOXmfy+Kwxc2GpZTvbWZnV8S6pfrS46NSKZnZLnevX9FlS1jGc8BUd3/NzAYBo929ZzmWV+6YSluumT0PLHP335ZQ/logw91vruhYpPrQFYFUCWZW38z+HZ6tf25mh7Q0amYtzGx2xBlzv3D8IDP7OJz372ZW2gF6NtA5nPfOcFmLzez2cFw9M3s7bP9+sZkNC8fPMrMMM3sMSAvjeDmctiv8+7fIM/TwSuRiM0sxs8fNbJ4Fbcz/LIqP5WPCxsbM7CQL+pn4NPx7dPhL3IeBYWEsw8LYJ4br+bSoz1GSUKLb3tZLr6JewEGChsQygTcJfgV/RDitKcGvKvOuaHeFf38B3Bu+TwHSw7KzgXrh+FHA/UWs7znC/gqAS4H/EDTe9jlQj6B54y+A44CLgWci5m0Q/p1FcPadH1NEmbwYhwLPh+9rEbQimQbcCNwXjq8NzAc6FBHnrojt+zswOBw+AqgZvv8x8Hr4/lrgyYj5fwf8NHzfkKANonqJ3t96JfZV7ZqYkGpjr7v3zhsws1Tgd2Z2OkHTCa2AI4HvIuaZB0wMy77l7plm1h/oBnwYNq1Ri+BMuiiPm9l9wCaCFlrPBN70oAE3zOwNoB8wHRhtZr8nqE6aU4bt+hcw1sxqA4OB2e6+N6yO6mk/9KLWAOgCrCg0f5qZZQLtgQXAuxHlnzezLgQtUaYWs/5BwPlmdlc4XAdoS9Vuj0jKSYlAqoorCXqfOsHdD5jZSoKDWD53nx0minOAF83scWAb8K67D49iHXe7+2t5A2b246IKufsyMzuBoL2XR81shrs/HM1GuPs+M5tF0HTyMGBS3uqAW9z9nVIWsdfde5tZA2AqcBMwlqC9nZnuPjS8sT6rmPkNuNjdl0YTryQH3SOQqqIBsDFMAmcA7QoXMLN2YZlngGcJuvv7BDjNzPLq/OuaWdco1zkbuDCcpx5Btc4cM2sJ7HH3l4DR4XoKOxBemRRlMkFDYf0IGlMj/PtfefOYWddwnUVy9x3ArcBd4TwNgLXh5GsjimYTVJHleQe4xcLLIzM7rrh1SPJQIpCq4mUgw8zmE1wdfFVEmQFAppl9SlCP/0d330RwYJxkZosIEsMx0azQ3RcS3DuYS3DPYIK7fwr0AOaGVTT3Ar8pYvbxwKK8m8WFzCDol/Y9D7pfhKCfiCXAQgs6Lf8LpVyxh7F8RtA08/8QXJ18SHD/IM9MoFvezWKCK4fUMLbF4bAkOT0+KiKS5HRFICKS5JQIRESSnBKBiEiSUyIQEUlySgQiIklOiUBEJMkpEYiIJLn/D6Z4SBfAocmsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import the ROC curve function from scikit-learn\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "#Plot the ROC curve using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plot_roc_curve(lr, features_test, output_test)\n",
    "plt.title('Test ROC Curve for Logistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using scikit-learn and matplotlib, plot the ROC curves for the test data predictions from the Decision Tree and KNN models.  Which model has the highest AUC value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the ROC curve using matplotlib for the Decision Tree model\n",
    "plot_roc_curve(##Enter your code here##)\n",
    "plt.title('Test ROC Curve for Decision Tree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the ROC curve using matplotlib for the KNN model\n",
    "plot_roc_curve(##Enter your code here##)\n",
    "plt.title('Test ROC Curve for KNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Practice\n",
    "Each of the models built above have [hyperparameters](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)) or variables that can be adjusted to change the way the model makes its predictions.  Your models used the default settings within scikit-learn.\n",
    "\n",
    "You can now go back and adjust these hyperparameters to see how they affect the evaulation of your model (see the [scikit-learn](https://scikit-learn.org/stable/supervised_learning.html) documentation for more details)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "There are many other methodologies for building binary classification models.  Below are some links to further explore these types of models:\n",
    "* https://medium.com/fuzz/machine-learning-classification-models-3040f71e2529\n",
    "* https://towardsdatascience.com/solving-a-simple-classification-problem-with-python-fruits-lovers-edition-d20ab6b071d2\n",
    "\n",
    "There are also other metrics you can use to evaluate classification models.  Below are additional links to other evaluation metrics.  The exact evaluation metric to use depends on your priorities.\n",
    "* [Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall)\n",
    "* [Sensitivity and Specificity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)\n",
    "* [Lift Curves](https://towardsdatascience.com/the-lift-curve-unveiled-998851147871)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
